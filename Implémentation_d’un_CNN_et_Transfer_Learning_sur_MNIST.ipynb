{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0XmkY2g3GaA4",
        "outputId": "0ba092e7-81e8-447f-9df6-b14dbef6da66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.19.0\n"
          ]
        }
      ],
      "source": [
        "# 0. Install / Imports\n",
        "try:\n",
        "    import tensorflow as tf\n",
        "except:\n",
        "    !pip install -q tensorflow\n",
        "    import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import layers, models, utils, optimizers, losses, callbacks\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import VGG16, ResNet50\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input as vgg_preprocess\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input as resnet_preprocess\n",
        "\n",
        "print(\"TensorFlow version:\", tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Load data\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "print(\"Shapes:\", x_train.shape, y_train.shape, x_test.shape, y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hb37phn2GjTy",
        "outputId": "c6625a79-95db-4e63-e98f-f30bf8b3d8f0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Shapes: (60000, 28, 28) (60000,) (10000, 28, 28) (10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# show class distribution train\n",
        "dist = pd.Series(y_train).value_counts().sort_index()\n",
        "print(\"Distribution (train):\")\n",
        "print(dist)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fhjAcFDvGoWi",
        "outputId": "5b571173-26f4-4396-805c-cd6418748755"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distribution (train):\n",
            "0    5923\n",
            "1    6742\n",
            "2    5958\n",
            "3    6131\n",
            "4    5842\n",
            "5    5421\n",
            "6    5918\n",
            "7    6265\n",
            "8    5851\n",
            "9    5949\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize some images\n",
        "fig, axes = plt.subplots(2,5, figsize=(10,4))\n",
        "for i, ax in enumerate(axes.flatten()):\n",
        "    ax.imshow(x_train[i], cmap='gray')\n",
        "    ax.set_title(f\"label: {y_train[i]}\")\n",
        "    ax.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "id": "vvsPlqWpGriG",
        "outputId": "c38e591d-5440-4f0b-dfc9-aef46249dd67"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x400 with 10 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxsAAAFXCAYAAADK21P3AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAANCpJREFUeJzt3Xl0VFXW9/FdTBmYkYBEJUQQmcQw2QSQiCAqQ3ACRRkdmFoQbQFRWkBAAQVEaQRBoUV8MLYCyqMPDgQZtG0GsRskEtMEZVCCDCEJJEDu+4ev6K19NUWlTqpu5ftZi7X6/HLq1iZ9LLJTde7xWJZlCQAAAAAEWJlgFwAAAAAgPNFsAAAAADCCZgMAAACAETQbAAAAAIyg2QAAAABgBM0GAAAAACNoNgAAAAAYQbMBAAAAwAiaDQAAAABGuLrZWLp0qXg8HsnMzLzgx1533XXSrFmzgNZTr149GTRoUECvidDF+kOwsQYRTKw/BBPrzz1c3WyEk8zMTPF4PI5/VqxYEezyUAoUFhbKzJkzJT4+XiIjI6V58+byP//zP8EuC6XU8uXLxePxSKVKlYJdCkqJadOmSXJystSuXVs8Ho9MmjQp2CWhFPn222/ljjvukOrVq0t0dLR06NBBUlNTg11WQJQLdgGw69u3r3Tr1s2WJSYmBqkalCZPPPGETJ8+XR544AFp06aNrF69Wu6++27xeDxy1113Bbs8lCI5OTkyduxYqVixYrBLQSkyYcIEufjii6VFixaydu3aYJeDUuT777+XxMREKVu2rIwZM0YqVqwoS5Yska5du8onn3wiHTt2DHaJxUKzEWJatmwp/fr1C3YZKGUOHDggs2bNkj//+c8yb948ERG5//77JSkpScaMGSO9e/eWsmXLBrlKlBZTp06VypUrS6dOnWTVqlXBLgelxN69e6VevXpy5MgRiYmJCXY5KEWmT58ux48fl507d8qVV14pIiIPPPCANGrUSB5++GHZtm1bkCssnrD7GNXq1aule/fuEhsbKxEREVK/fn2ZMmWKnDt3znH+tm3bpF27dhIVFSXx8fGyYMECNSc/P18mTpwoDRo0kIiICLnssstk7Nixkp+fX2Q9GRkZkpGRcUF/h9zcXCkoKLigxyA0uHX9rV69Ws6cOSMjRow4n3k8Hhk+fLjs379fPv/88yKvgdDg1jX4i/T0dJkzZ47Mnj1bypXj92Fu4+b1V69ePZ/mIXS5df1t3LhRWrRocb7REBGJjo6W5ORk2b59u6Snpxd5jVAWdq/kS5culUqVKskjjzwilSpVknXr1smTTz4p2dnZ8uyzz9rmHjt2TLp16yZ9+vSRvn37SkpKigwfPlwqVKgg9957r4j8/Dn25ORk2bRpkwwZMkQaN24s//nPf2TOnDmyZ8+eIn/r1rlzZxERnzcwTZ48WcaMGSMej0datWol06ZNk65du17w9wHB4db19+WXX0rFihWlcePGtvyaa645//UOHTpcwHcCweLWNfiL0aNHS6dOnaRbt26SkpJywX9/BJfb1x/cza3rLz8/X6pXr67y6OhoEfm5Kbriiit8/C6EIMvFlixZYomItXfv3vNZXl6emjd06FArOjraOn369PksKSnJEhFr1qxZ57P8/HwrISHBqlWrllVQUGBZlmUtW7bMKlOmjLVx40bbNRcsWGCJiLV58+bzWVxcnDVw4EDbvLi4OCsuLq7Iv8u+ffusrl27Wi+99JL17rvvWs8//7xVt25dq0yZMtaaNWuKfDxKXjitv+7du1uXX365ynNzcy0RsR577LEir4GSF05r0LIsa82aNVa5cuWsXbt2WZZlWQMHDrQqVqzo02NR8sJt/f0iKyvLEhFr4sSJF/Q4lKxwWn89e/a0qlWrZmVnZ9vyxMRES0Ss5557rshrhLKw+xhVVFTU+f998uRJOXLkiFx77bWSl5cnaWlptrnlypWToUOHnh9XqFBBhg4dKocPHz7/+bi33npLGjduLI0aNZIjR46c/3P99deLiBR5p4DMzEyffqNSt25dWbt2rQwbNkx69uwpDz30kHz55ZcSExMjf/nLX3z96yPI3Lr+Tp06JRERESqPjIw8/3W4g1vXYEFBgTz88MMybNgwadKkia9/XYQYt64/hAe3rr/hw4fL8ePH5c4775Qvv/xS9uzZI6NHj5atW7eKiPv/DQ67j1Ht2rVLJkyYIOvWrZPs7Gzb106cOGEbx8bGqrudNGzYUER+XiBt27aV9PR02b179+9uFjt8+HAAq7erUaOGDB48WKZPny779++XSy+91NhzITDcuv6ioqIcP396+vTp81+HO7h1Dc6ZM0eOHDkikydPDsj1EBxuXX8ID25dfzfffLO8+OKL8thjj0nLli1FRKRBgwYybdo0GTt2rOtvAR5Wzcbx48clKSlJqlSpIk899ZTUr19fIiMjZfv27TJu3DgpLCy84GsWFhbKVVddJbNnz3b8+mWXXVbcsv/QL9c/evQozUaIc/P6q1OnjqSmpoplWeLxeM7nhw4dEpGfX5QR+ty6Bk+cOCFTp06VESNGSHZ29vkfEnJycsSyLMnMzJTo6GipVatWsZ8L5rh1/SE8uH39PfjggzJ48GD597//LRUqVJCEhAR55ZVXROTXJsitwqrZWL9+vfz000/yzjvv2O5JvHfvXsf5Bw8elNzcXFtnu2fPHhH59a4U9evXl6+++ko6d+5s+yGspPz3v/8VEeE2fC7g5vWXkJAgixcvlt27d9s+wvLFF1+c/zpCn1vX4LFjxyQnJ0dmzpwpM2fOVF+Pj4+XXr16cRvcEOfW9YfwEA7rr2LFiraz1T7++GOJioqS9u3bG39uk8Jqz8Yv5wBYlnU+KygokPnz5zvOP3v2rCxcuNA2d+HChRITEyOtWrUSEZE+ffrIgQMHZNGiRerxp06dktzc3D+sydfbnmVlZanswIED8uqrr0rz5s2lTp06RV4DweXm9derVy8pX768rVbLsmTBggVyySWXSLt27Yq8BoLPrWuwVq1asnLlSvWnU6dOEhkZKStXrpTx48f/4TUQfG5dfwgP4bb+PvvsM3nnnXfkvvvuk6pVq/p1jVARVu9stGvXTqpXry4DBw6UUaNGicfjkWXLltkW3m/FxsbKjBkzJDMzUxo2bChvvvmm7NixQ15++WUpX768iIj0799fUlJSZNiwYZKamirt27eXc+fOSVpamqSkpMjatWuldevWv1uTr7c9Gzt2rGRkZEjnzp0lNjZWMjMzZeHChZKbmytz58717xuCEuXm9XfppZfK6NGj5dlnn5UzZ85ImzZtZNWqVbJx40ZZvnw5B/q5hFvXYHR0tNxyyy0qX7VqlfzrX/9y/BpCj1vX3y+WLVsm+/btk7y8PBER2bBhg0ydOvV8HXFxcRfy7UAJc/P627dvn/Tp00eSk5Pl4osvll27dsmCBQukefPm8vTTT/v3DQklQbkHVoA43fZs8+bNVtu2ba2oqCgrNjbWGjt2rLV27VpLRKzU1NTz85KSkqymTZtaW7dutRITE63IyEgrLi7OmjdvnnqegoICa8aMGVbTpk2tiIgIq3r16larVq2syZMnWydOnDg/rzi3PXvjjTesjh07WjExMVa5cuWsmjVrWrfeequ1bdu2C/22oISE0/qzLMs6d+6c9fTTT1txcXFWhQoVrKZNm1qvv/76hXxLUMLCbQ1649a3oS3c1t8vt0N1+vPb2hEawmn9HT161OrVq5d18cUXWxUqVLDi4+OtcePGqVvhupXHsn6n5QMAAACAYgirPRsAAAAAQgfNBgAAAAAjaDYAAAAAGEGzAQAAAMAImg0AAAAARtBsAAAAADDC50P9SuKYdrhPSd05mfUHJyV5527WIJzwGohgYv0hmHxdf7yzAQAAAMAImg0AAAAARtBsAAAAADCCZgMAAACAETQbAAAAAIyg2QAAAABgBM0GAAAAACNoNgAAAAAYQbMBAAAAwAiaDQAAAABG0GwAAAAAMIJmAwAAAIARNBsAAAAAjKDZAAAAAGAEzQYAAAAAI2g2AAAAABhBswEAAADACJoNAAAAAEaUC3YBAIqvVatWKnvwwQdt4wEDBqg5r732mspefPFFlW3fvr0Y1QEAgNKKdzYAAAAAGEGzAQAAAMAImg0AAAAARtBsAAAAADDCY1mW5dNEj8d0LUFXtmxZlVWtWtXv63lv0I2OjlZzrrzySpX9+c9/Vtlzzz1nG/ft21fNOX36tMqmT5+ussmTJ+ti/eTj8im20rD+fJWQkKCydevWqaxKlSp+Xf/EiRMqu+iii/y6lmkltf5EWIPB1rlzZ9t4+fLlak5SUpLKvvnmG2M1ifAa6HYTJkxQmdO/kWXK2H83e91116k5n376acDq8hXrD8Hk6/rjnQ0AAAAARtBsAAAAADCCZgMAAACAETQbAAAAAIxw/QnidevWVVmFChVU1q5dO5V16NDBNq5WrZqac/vtt/tfnA/279+vshdeeEFlt956q2188uRJNeerr75SWTA2rCFwrrnmGpW9/fbbKnO6kYH3xi2nNVNQUKAyp83gbdu2tY2dThR3uhacdezYUWVO3/eVK1eWRDmu0KZNG9t4y5YtQaoEbjVo0CCVjRs3TmWFhYVFXqskb04BuB3vbAAAAAAwgmYDAAAAgBE0GwAAAACMcNWeDV8PMyvOQXwmOX0O1OlAoZycHJV5H2B16NAhNefYsWMqM32gFfznfchjy5Yt1ZzXX39dZXXq1PHr+dLT01U2c+ZMla1YsUJlmzdvto2d1u0zzzzjV12lkdOBYFdccYXKSuueDe8D1ERE4uPjbeO4uDg1h4PH8Eec1kxkZGQQKkEo+tOf/qSyfv36qczp8NCmTZsWef1HH31UZQcPHlSZ935iEf2zwBdffFHk84US3tkAAAAAYATNBgAAAAAjaDYAAAAAGEGzAQAAAMAIV20Q/+6771T2008/qcz0BnGnjTnHjx9XWadOnWxjp0PPli1bFrC64C4LFy60jfv27Wv0+Zw2oFeqVEllTgdBem9obt68ecDqKo0GDBigss8//zwIlYQmp5sgPPDAA7ax080T0tLSjNUE9+nSpYttPHLkSJ8e57SOevToYRv/+OOP/heGkHDnnXfaxnPnzlVzatasqTKnG1GsX79eZTExMbbxs88+61NdTtf3vtZdd93l07VCBe9sAAAAADCCZgMAAACAETQbAAAAAIyg2QAAAABghKs2iB89elRlY8aMUZn3Ri4RkS+//FJlL7zwQpHPuWPHDpXdcMMNKsvNzVWZ94mSDz30UJHPh/DUqlUrlXXv3t029vX0Y6cN3O+9957KnnvuOdvY6aRSp/8unE6iv/76621jTmouHqcTsvGrxYsXFzknPT29BCqBWzidurxkyRLb2Nebxzht5N23b59/haHElSunf7Rt3bq1yhYtWmQbR0dHqzkbNmxQ2ZQpU1S2adMmlUVERNjGKSkpak7Xrl1V5mTr1q0+zQtV/IsHAAAAwAiaDQAAAABG0GwAAAAAMIJmAwAAAIARrtog7mTVqlUqW7duncpOnjypsquvvto2vu+++9Qc7022Is6bwZ3s2rXLNh4yZIhPj4O7JSQkqOyjjz5SWZUqVWxjy7LUnA8++EBlTieNJyUlqWzChAm2sdOm26ysLJV99dVXKissLLSNvTe3izifUL59+3aVlTZOp63Xrl07CJW4hy8beZ3+m0LpNXDgQJXFxsYW+Tink59fe+21QJSEIOnXr5/KfLnphNNrivcp4yIi2dnZPtXh/VhfN4Pv379fZX//+999emyo4p0NAAAAAEbQbAAAAAAwgmYDAAAAgBE0GwAAAACMcP0GcSe+bt45ceJEkXMeeOABlb355psq895Ai9KhYcOGKnM61d5pw+uRI0ds40OHDqk5TpvCcnJyVPa///u/PmWBEhUVpbK//OUvKrvnnnuM1eAW3bp1U5nT96+0ctosHx8fX+TjDhw4YKIcuEDNmjVVdu+996rM+9/l48ePqzlTp04NWF0oeU6neT/++OMqc7oBy/z5821j75uqiPj+86STJ554wq/HjRo1SmVON3NxE97ZAAAAAGAEzQYAAAAAI2g2AAAAABgRlns2fDVp0iTbuFWrVmqO02FpXbp0UdmHH34YsLoQmiIiIlTmdOij02f0nQ6VHDBggG28detWNcdNn+2vW7dusEsISVdeeaVP87wPAS0tnP4bctrHsWfPHtvY6b8phJ969eqp7O233/brWi+++KLKUlNT/boWSt6TTz6pMqf9GQUFBSpbu3atysaNG2cbnzp1yqc6IiMjVeZ0YJ/3v4kej0fNcdoztHr1ap/qcBPe2QAAAABgBM0GAAAAACNoNgAAAAAYQbMBAAAAwIhSvUE8NzfXNnY6wG/79u0qW7RokcqcNpl5b/j929/+puY4HTSD0NSiRQuVOW0Gd9KrVy+Vffrpp8WuCeFjy5YtwS6hWKpUqaKym266yTbu16+fmuO0sdKJ9+FdTge0Ifx4ryERkebNm/v02E8++cQ2njt3bkBqQsmoVq2abTxixAg1x+lnKKfN4LfccotfNTRo0EBly5cvV5nTDYa8/eMf/1DZzJkz/arLbXhnAwAAAIARNBsAAAAAjKDZAAAAAGAEzQYAAAAAI0r1BnFvGRkZKhs0aJDKlixZorL+/fsXmVWsWFHNee2111R26NChPyoTQTJ79myVOZ0I6rTx2+2bwcuUsf9eorCwMEiVhK8aNWoE7FpXX321ypzWapcuXWzjSy+9VM2pUKGCyu655x6Vea8REX0i7xdffKHm5Ofnq6xcOf1P07Zt21SG8OK0iXf69Ok+PXbTpk0qGzhwoG184sQJv+pCcHi/9tSsWdOnx40aNUpltWrVUtngwYNt4+TkZDWnWbNmKqtUqZLKnDaqe2evv/66muN9o6JwxTsbAAAAAIyg2QAAAABgBM0GAAAAACNoNgAAAAAYwQbxIqxcuVJl6enpKnPaPNy5c2fb+Omnn1Zz4uLiVDZt2jSVHThw4A/rROD16NHDNk5ISFBznDaFvfvuu6ZKChrvDeFOf+8dO3aUUDXu4r1JWsT5+7dgwQKVPf744349p9MJy04bxM+ePWsb5+XlqTlff/21yl599VWVbd26VWXeN0b48ccf1Zz9+/erLCoqSmVpaWkqg7vVq1fPNn777bf9vtZ///tflTmtN7hHQUGBbZyVlaXmxMTEqGzv3r0qc3rN9cXBgwdVlp2drbI6deqo7MiRI7bxe++951cN4YB3NgAAAAAYQbMBAAAAwAiaDQAAAABG0GwAAAAAMIIN4n7YuXOnyvr06aOynj172sZOJ48PHTpUZVdccYXKbrjhhgspEQHgvUnV6STlw4cPq+zNN980VlOgRUREqGzSpElFPm7dunUqGz9+fCBKCjsjRoxQ2b59+1TWrl27gD3nd999p7JVq1apbPfu3bbxP//5z4DV4GTIkCEqc9rg6bTZF+Fn3LhxtrH3jSguhK8njcM9jh8/bhs7nTC/Zs0aldWoUUNlGRkZKlu9erVtvHTpUjXn6NGjKluxYoXKnDaIO80rrXhnAwAAAIARNBsAAAAAjKDZAAAAAGAEezYCxPuzhSIiy5Yts40XL16s5pQrp/8v6Nixo8quu+4623j9+vUXVB/MyM/PV9mhQ4eCUEnRnPZnTJgwQWVjxoxRmffBa7NmzVJzcnJyilFd6TJjxoxglxAU3ged/p7iHO6G0OR0KGrXrl39upb3Z+1FRL755hu/rgX3+OKLL1TmtOcrkJx+HktKSlKZ034j9p79inc2AAAAABhBswEAAADACJoNAAAAAEbQbAAAAAAwgg3ifmjevLnK7rjjDpW1adPGNnbaDO7k66+/VtmGDRt8rA4l6d133w12Cb/Le0Om08bvO++8U2VOmy9vv/32gNUFFGXlypXBLgEB9uGHH6qsevXqRT7O6aDJQYMGBaIkoEjeh/uKOG8GtyxLZRzq9yve2QAAAABgBM0GAAAAACNoNgAAAAAYQbMBAAAAwAg2iP/GlVdeqbIHH3xQZbfddpvKLr74Yr+e89y5cypzOoHaaUMSzPJ4PH84FhG55ZZbVPbQQw+ZKul3Pfzwwyr761//ahtXrVpVzVm+fLnKBgwYELjCAEBELrroIpX58u/a/PnzVZaTkxOQmoCirF27NtglhAXe2QAAAABgBM0GAAAAACNoNgAAAAAYQbMBAAAAwIhSs0HcaQN33759bWOnzeD16tULWA1bt25V2bRp01QWyqdSlybeJ4I6nRDqtK5eeOEFlb366qsq++mnn2zjtm3bqjn9+/dX2dVXX62ySy+9VGXfffedbey00c1p8yVQkpxuvNCwYUOVOZ0kjdC0ZMkSlZUp49/vNj/77LPilgP47cYbbwx2CWGBdzYAAAAAGEGzAQAAAMAImg0AAAAARrh+z0bt2rVV1qRJE5XNmzdPZY0aNQpYHV988YXKnn32Wdt49erVag6H9blb2bJlVTZixAiV3X777SrLzs62ja+44gq/63D6XHNqaqpt/OSTT/p9fcAUp71Q/n6+HyUvISFBZV26dFGZ0791BQUFtvHf/vY3NefHH3/0vzigmC6//PJglxAWeEUHAAAAYATNBgAAAAAjaDYAAAAAGEGzAQAAAMCIkN4gXqNGDdt44cKFao7T5rRAbuhx2ng7a9YslTkdmHbq1KmA1YGS9/nnn9vGW7ZsUXPatGnj07WcDv9zurmBN++D/0REVqxYobKHHnrIpzoAN0hMTFTZ0qVLS74QFKlatWoqc3q9c3LgwAHb+NFHHw1ESUDAbNy4UWVON7DgZj9/jHc2AAAAABhBswEAAADACJoNAAAAAEbQbAAAAAAwIigbxP/0pz+pbMyYMSq75pprbONLLrkkoHXk5eXZxi+88IKa8/TTT6ssNzc3oHUgNO3fv982vu2229ScoUOHqmzChAl+Pd/cuXNV9tJLL6ns22+/9ev6QCjyeDzBLgEAHO3cuVNl6enpKnO6MVH9+vVt46ysrMAV5jK8swEAAADACJoNAAAAAEbQbAAAAAAwgmYDAAAAgBFB2SB+6623+pT54uuvv1bZmjVrVHb27FmVeZ8Efvz4cb9qQOlw6NAhlU2aNMmnDIDIBx98oLLevXsHoRIESlpamso+++wzlXXo0KEkygGMc7px0OLFi1U2bdo023jkyJFqjtPPsOGIdzYAAAAAGEGzAQAAAMAImg0AAAAARtBsAAAAADDCY1mW5dNETnmFAx+XT7Gx/uCkpNafCGsQzngNRDCx/kpelSpVVJaSkqKyLl262MbvvPOOmjN48GCV5ebmFqO6kuXr+uOdDQAAAABG0GwAAAAAMIJmAwAAAIAR7NlAsfB5UQQTezYQbLwGIphYf6HBaR+H96F+w4cPV3OaN2+uMjcd9MeeDQAAAABBRbMBAAAAwAiaDQAAAABG0GwAAAAAMIIN4igWNqchmNggjmDjNRDBxPpDMLFBHAAAAEBQ0WwAAAAAMIJmAwAAAIARNBsAAAAAjPB5gzgAAAAAXAje2QAAAABgBM0GAAAAACNoNgAAAAAYQbMBAAAAwAiaDQAAAABG0GwAAAAAMIJmAwAAAIARNBsAAAAAjKDZAAAAAGAEzQYAAAAAI2g2AAAAABhBswEAAADACFc3G0uXLhWPxyOZmZkX/NjrrrtOmjVrFtB66tWrJ4MGDQroNRG6WH8INtYggon1h2Bi/bmHq5uNcJKWliZjx46VhIQEqVy5stSpU0e6d+8uW7duDXZpKCWmTZsmycnJUrt2bfF4PDJp0qRgl4RS5ODBg9KvXz+58sorpXLlylKtWjW55ppr5O9//7tYlhXs8lAK8BqIULF8+XLxeDxSqVKlYJcSEDQbIWLx4sWyaNEiad26tcyaNUseeeQR+eabb6Rt27by8ccfB7s8lAITJkyQLVu2SIsWLYJdCkqhI0eOyP79++WOO+6Q5557TqZOnSp16tSRQYMGyRNPPBHs8lAK8BqIUJCTkyNjx46VihUrBruUgCkX7ALws759+8qkSZNsXey9994rjRs3lkmTJkmXLl2CWB1Kg71790q9evXkyJEjEhMTE+xyUMo0b95c1q9fb8sefPBB6dmzp7zwwgsyZcoUKVu2bHCKQ6nAayBCwdSpU6Vy5crSqVMnWbVqVbDLCYiwe2dj9erV0r17d4mNjZWIiAipX7++TJkyRc6dO+c4f9u2bdKuXTuJioqS+Ph4WbBggZqTn58vEydOlAYNGkhERIRcdtllMnbsWMnPzy+ynoyMDMnIyChyXqtWrdTbZRdddJFce+21snv37iIfj9Dg1vUn8vPnTeF+bl6DTurVqyd5eXlSUFDg9zVQcty8/ngNdD83rz8RkfT0dJkzZ47Mnj1bypULn/cDwudv8v8tXbpUKlWqJI888ohUqlRJ1q1bJ08++aRkZ2fLs88+a5t77Ngx6datm/Tp00f69u0rKSkpMnz4cKlQoYLce++9IiJSWFgoycnJsmnTJhkyZIg0btxY/vOf/8icOXNkz549RXadnTt3FhHxawOTiMgPP/wgNWvW9OuxKHnhtv7gPm5fg6dOnZLc3FzJycmRTz/9VJYsWSKJiYkSFRV1wd8LlDy3rz+4m9vX3+jRo6VTp07SrVs3SUlJueC/f8iyXGzJkiWWiFh79+49n+Xl5al5Q4cOtaKjo63Tp0+fz5KSkiwRsWbNmnU+y8/PtxISEqxatWpZBQUFlmVZ1rJly6wyZcpYGzdutF1zwYIFlohYmzdvPp/FxcVZAwcOtM2Li4uz4uLi/Pr7bdiwwfJ4PNZf//pXvx4Ps8J1/WVlZVkiYk2cOPGCHoeSF45r8JlnnrFE5Pyfzp07W999953Pj0fJCcf1Z1m8BrpFuK2/NWvWWOXKlbN27dplWZZlDRw40KpYsaJPjw11Yfcxqt/+9uvkyZNy5MgRufbaayUvL0/S0tJsc8uVKydDhw49P65QoYIMHTpUDh8+LNu2bRMRkbfeeksaN24sjRo1kiNHjpz/c/3114uISGpq6h/Wk5mZ6ddvVA4fPix33323xMfHy9ixYy/48QiOcFl/cC+3r8G+ffvKRx99JG+88YbcfffdIvLzux1wB7evP7ibW9dfQUGBPPzwwzJs2DBp0qSJr39d1wi7j1Ht2rVLJkyYIOvWrZPs7Gzb106cOGEbx8bGqt3+DRs2FJGfF0jbtm0lPT1ddu/e/bubxQ4fPhzA6n+Wm5srPXr0kJMnT8qmTZvC5tZnpUE4rD+4m9vXYFxcnMTFxYnIz43HkCFDpEuXLvLNN9/wUSoXcPv6g7u5df3NmTNHjhw5IpMnTw7I9UJNWDUbx48fl6SkJKlSpYo89dRTUr9+fYmMjJTt27fLuHHjpLCw8IKvWVhYKFdddZXMnj3b8euXXXZZccu2KSgokNtuu03+/e9/y9q1awN+6AzMCYf1B3cLxzV4xx13yKJFi2TDhg1y4403Gn0uFE84rj+4h1vX34kTJ2Tq1KkyYsQIyc7OPt8k5eTkiGVZkpmZKdHR0VKrVq1iP1ewhFWzsX79evnpp5/knXfekY4dO57P9+7d6zj/4MGDkpuba+ts9+zZIyK/3pWifv368tVXX0nnzp3F4/GYK15+XtQDBgyQTz75RFJSUiQpKcno8yGw3L7+4H7huAZ/+QiV928lEXrCcf3BPdy6/o4dOyY5OTkyc+ZMmTlzpvp6fHy89OrVy9W3wQ2rPRu/3IPd+s1pswUFBTJ//nzH+WfPnpWFCxfa5i5cuFBiYmKkVatWIiLSp08fOXDggCxatEg9/pe7pvyRC7nt2ciRI+XNN9+U+fPny2233ebTYxA63L7+4H5uXoNZWVmO+SuvvCIej0datmxZ5DUQXG5ef3A/t66/WrVqycqVK9WfTp06SWRkpKxcuVLGjx//h9cIdWH1zka7du2kevXqMnDgQBk1apR4PB5ZtmyZbeH9VmxsrMyYMUMyMzOlYcOG8uabb8qOHTvk5ZdflvLly4uISP/+/SUlJUWGDRsmqamp0r59ezl37pykpaVJSkqKrF27Vlq3bv27Nfl627Pnn39e5s+fL4mJiRIdHS2vv/667eu33nprWJ0mGY7cvP5ERJYtWyb79u2TvLw8ERHZsGGDTJ069Xwdv3yOHqHLzWtw2rRpsnnzZrnpppukbt26cvToUXn77bdly5YtMnLkSGnQoIF/3xSUGDevPxFeA93OresvOjpabrnlFpWvWrVK/vWvfzl+zXWCdBesgHC67dnmzZuttm3bWlFRUVZsbKw1duxYa+3atZaIWKmpqefnJSUlWU2bNrW2bt1qJSYmWpGRkVZcXJw1b9489TwFBQXWjBkzrKZNm1oRERFW9erVrVatWlmTJ0+2Tpw4cX5ecW57NnDgQNvtHr3//PbviNAQTuvvl5p+b/39tnaEjnBagx9++KHVo0cPKzY21ipfvrxVuXJlq3379taSJUuswsLCC/3WoASE0/r7pSZeA90j3Naft3C69a3Hsn6n5QMAAACAYgirPRsAAAAAQgfNBgAAAAAjaDYAAAAAGEGzAQAAAMAImg0AAAAARtBsAAAAADDC50P9TB3TDncrqTsns/7gpCTv3M0ahBNeAxFMrD8Ek6/rj3c2AAAAABhBswEAAADACJoNAAAAAEbQbAAAAAAwgmYDAAAAgBE0GwAAAACMoNkAAAAAYATNBgAAAAAjaDYAAAAAGEGzAQAAAMAImg0AAAAARtBsAAAAADCCZgMAAACAETQbAAAAAIyg2QAAAABgBM0GAAAAACNoNgAAAAAYQbMBAAAAwIhywS4AwM/mzp2rslGjRqls586dKuvRo4fK9u3bF5jCAABASPvkk09U5vF4VHb99deXRDk2vLMBAAAAwAiaDQAAAABG0GwAAAAAMIJmAwAAAIARbBAPkMqVK6usUqVKtnH37t3VnJiYGJXNnj1bZfn5+cWoDqGoXr16tnG/fv3UnMLCQpU1btxYZY0aNVIZG8RRlIYNG9rG5cuXV3M6duyosvnz56vMaa0G0urVq23ju+66S80pKCgwWgPMclp/7dq1U9nTTz+tsvbt2xupCQhFc+bMUZnTfyuvvfZaSZRTJN7ZAAAAAGAEzQYAAAAAI2g2AAAAABhBswEAAADACDaIF8F7E6+IyLhx41SWmJiosmbNmvn1nHXq1FGZ00nScLesrCzbeMOGDWpOcnJySZWDMNK0aVOVDRo0SGW9e/e2jcuU0b9/io2NVZnTZnDLsi6gwgvn/d/CggUL1JzRo0erLDs721RJCLCqVauqLDU1VWU//PCDyi6++GKf5gFuNH36dNt42LBhas6ZM2dU5nSqeDDwzgYAAAAAI2g2AAAAABhBswEAAADAiFK9Z8P7IDSnz/vec889KouKilKZx+NR2ffff28bnzx5Us1xOqCtT58+KvM+RCstLU3Ngbvk5ubaxhzCh0B55plnVNatW7cgVGLOgAEDVPbKK6+obPPmzSVRDkqQ0/4M9mwgnLVt29Y2djoAc9OmTSpLSUkxVtOF4J0NAAAAAEbQbAAAAAAwgmYDAAAAgBE0GwAAAACMCMsN4k4HA82YMUNld955p21cuXJlv58zPT1dZTfeeKNt7LShx2mjd82aNX3K4G7VqlWzja+++urgFIKw89FHH6nMlw3ihw8fVpnTpmunw/+cDvrz1q5dO5UlJSUV+Tjgt5xuyAIUV8eOHVX2xBNPqKxv374qO3r0aMDqcLq+9yHRGRkZas6jjz4asBoCjXc2AAAAABhBswEAAADACJoNAAAAAEbQbAAAAAAwIiw3iN96660qu//++wN2faeNOTfccIPKvE8Qb9CgQcBqgPtFR0fbxnXr1vX7Wm3atFGZ980HOKG89HjppZdUtmrVqiIfd+bMGZUF8hTmKlWqqGznzp0qi42NLfJaTn+frVu3+lUX3MWyLJVFRkYGoRKEk5dfflllV1xxhcqaNGmiMqfTu/31+OOPq+yiiy6yjR944AE156uvvgpYDYHGOxsAAAAAjKDZAAAAAGAEzQYAAAAAI2g2AAAAABgRlhvEe/fu7dfjMjMzVbZlyxaVjRs3TmXem8GdNG7c2K+6EJ4OHjxoGy9dulTNmTRpkk/Xcpp3/Phx23jevHk+Vga3O3v2rMp8eY0y7cYbb1RZ9erV/brW/v37VZafn+/XteB+rVu3Vtk///nPIFQCt8rLy1OZ6ZsRJCQkqCwuLk5lhYWFxmooCbyzAQAAAMAImg0AAAAARtBsAAAAADCCZgMAAACAEWG5QdzpZMUhQ4ao7MMPP7SNv/32WzXn8OHDAaurdu3aAbsWws+UKVNU5usGcSAU3XXXXbax02tzVFSUX9d+8skn/XocQpfTjQ1OnDihsqpVq6qsfv36RmpC+PL+N/eqq65Sc3bv3q0yf0/qrlixosqcbjgUHR2tMu+bHfzjH//wq4Zg4Z0NAAAAAEbQbAAAAAAwgmYDAAAAgBFhuWfD+7A0kdD47HtiYmKwS4DLlCmjfx/gfbgPUNLuuecelT322GMqa9CggW1cvnx5v59zx44dtvGZM2f8vhZCk/dBpCIiGzduVFmPHj1KoBqEk8suu0xl3nvInPYMPfjggyrLysryq4bZs2erzOkQaqefYdu3b+/Xc4YK3tkAAAAAYATNBgAAAAAjaDYAAAAAGEGzAQAAAMCIsNwgHkijRo1SmdPBLL5wOjDGyWeffaayzz//3K/nhLs5bQa3LCsIlcBN6tWrp7L+/furrEuXLn5dv0OHDirzd11mZ2erzGmz+fvvv28bnzp1yq/nAxDemjVrprKVK1eqrGbNmrbxiy++qOZ8+umnftfx6KOP2saDBg3y6XHTpk3z+zlDFe9sAAAAADCCZgMAAACAETQbAAAAAIyg2QAAAABgRKnZIB4dHa2yJk2a2MYTJ05Uc7p16+bT9f096dnppMjBgwer7Ny5cz7VAaB0cdoM+e6776qsbt26JVHOBXM6Ifrll18OQiVws4suuijYJcCwcuX0j6z9+vVT2SuvvKIyX35GS0xMVHPGjx+vMqeTwGvUqKEy79PBPR6PmvPaa6+pbOHChSpzO97ZAAAAAGAEzQYAAAAAI2g2AAAAABhBswEAAADACNdvEC9fvrzKWrRoobK3335bZXXq1LGNnU6kddrA7XSa90033aQyp03p3pw2PN12220qmzt3rm1cUFBQ5LUBlE5OGxGdMn/5e0MMJz169FDZzTffrLIPPvjAr+ujdEhOTg52CTDsrrvuUtnixYtVZlmWypxen7799lvbuHXr1mqOU9arVy+VXXLJJSrz/hkzKytLzbn33ntVFo54ZwMAAACAETQbAAAAAIyg2QAAAABgBM0GAAAAACNctUG8QoUKKnPamP3OO+/4dL3JkyfbxuvWrVNzNm/erDKnkyKdHut0sq+3mJgYlT3zzDMq++6772zjVatWqTn5+flFPh/cpTgbcTt27Ggbz5s3LyA1IbTs3LlTZdddd53KnE7aXbt2rW18+vTpgNUlInLffffZxiNHjgzo9RH+UlNTVeZ0UwGEnzvvvNM2XrJkiZpz5swZlR0/flxld999t8qOHTtmG8+aNUvNSUpKUpnTpnGnG3B4b1SvWbOmmvP999+rzOn1OyMjQ2VuwjsbAAAAAIyg2QAAAABgBM0GAAAAACM8ltPpJ04TA3gglK+8D+x76qmn1JwxY8b4dC2nA6H69+9vGzt9zs9pT8X777+vspYtW6rM++C9mTNnqjlO+zqcDozx9vHHH6tsxowZKvP+TOLv2bFjh0/zvPm4fIotGOsvFJw7d05l/n7PmzdvrrKvv/7ar2uFipJafyKldw0WR9WqVW3jn376yafH9ezZU2Wheqgfr4Fm3X777Sp76623VOZ0KG+TJk1s43379gWusBARzuvPey9sXFycmjN16lSVOe3t8IX3ehERWbhwocoSExNV5sueDSdvvPGGygYMGFDk40KFr+uPdzYAAAAAGEGzAQAAAMAImg0AAAAARtBsAAAAADAiZA71K1u2rMqmTJliGz/66KNqTm5ursoee+wxla1YsUJl3hvCnQ5qcToIrUWLFipLT09X2fDhw21jp8OJqlSporJ27dqp7J577rGNk5OT1ZyPPvpIZU6cDpGJj4/36bEoWQsWLFDZ0KFD/brWkCFDVDZ69Gi/rgX44sYbbwx2CXC5s2fP+jTPaYNuREREoMtBCVq9erVt7HRgs9PPM/5yOnTPl8OZRUT69u2rMqcDV73t37/fp+u7He9sAAAAADCCZgMAAACAETQbAAAAAIyg2QAAAABgRMhsEHfavOq9ITwvL0/Ncdos++GHH6qsbdu2Khs8eLBtfPPNN6s5UVFRKnM6ydzpxEpfNi5lZ2er7P/+7/+KzJw2I919991FPp+IyMMPP+zTPARfWlpasEtAEJUvX9427tq1q5rjfcquiPNpyqZ5v56KiMydO7fE60B48d4kLOL8utioUSOVed8AY8SIEQGrC+aZfv2oWrWqbdy7d281x+kmPhkZGSpLSUkJXGFhiHc2AAAAABhBswEAAADACJoNAAAAAEbQbAAAAAAwwmNZluXTRIfTOQPp0KFDKouJibGN8/Pz1RynjWIVK1ZUWYMGDfyqa9KkSSp75plnVHbu3Dm/ru92Pi6fYjO9/txkz549Kqtfv36RjytTRv9uwem/C6fNb6GqpNafiPk12KFDB5U98cQTtvENN9yg5sTHx6sskKfq1qhRQ2XdunVT2YsvvqiyypUrF3l9p83sycnJKktNTS3yWsHAa2DJe/7551XmdIOC2rVr28anT582VVLQsP78N378eNt4ypQpak5WVpbK2rRpo7LSchK4N1/XH+9sAAAAADCCZgMAAACAETQbAAAAAIwImUP9fvjhB5V579mIiIhQc66++mqfrv/++++rbMOGDbbxqlWr1JzMzEyVldb9GQgNu3btUtnll19e5OMKCwtNlIMAmTdvnsqaNWtW5OPGjh2rspMnTwakJhHnfSItW7ZUmS+f3V2/fr3KXnrpJZWF6v4MhC6n9VdQUBCEShCK4uLiVHb//ffbxk5r6OWXX1ZZad2fURy8swEAAADACJoNAAAAAEbQbAAAAAAwgmYDAAAAgBEhs0G8Y8eOKrvllltsY6dNiYcPH1bZq6++qrJjx46pjM1jcCOnDWs9e/YMQiUIBcOHDw92CSLi/Fr83nvv2cYPPfSQmhOOB62h5FWpUkVlvXr1so1XrlxZUuUgxHz00Ucq8940/vrrr6s5EydONFZTacI7GwAAAACMoNkAAAAAYATNBgAAAAAjaDYAAAAAGOGxfDn2VUQ8Ho/pWuBCPi6fYmP9/crpJNQ1a9aorHHjxrax0/ewYcOGKsvIyChGdSWrpNafiPk1mJCQoLKRI0faxgMHDjRag9P/93l5eSrbuHGjypxuXLBz587AFBbCeA0seQcPHlRZ9erVVdaiRQvbOC0tzVhNwcL688348eNVNmXKFNu4d+/eag43Ffhjvq4/3tkAAAAAYATNBgAAAAAjaDYAAAAAGEGzAQAAAMAINoijWNichmAKpw3iTiIiImzjQYMGqTlTp05VmdNm2VWrVqnM+1Td1atXqzk//PBDEVWWbrwGlrwVK1aozPuGGCIiycnJtvG+ffuM1RQsrD8EExvEAQAAAAQVzQYAAAAAI2g2AAAAABhBswEAAADACDaIo1jYnIZgCvcN4gh9vAYimFh/CCY2iAMAAAAIKpoNAAAAAEbQbAAAAAAwgmYDAAAAgBE0GwAAAACMoNkAAAAAYATNBgAAAAAjaDYAAAAAGEGzAQAAAMAImg0AAAAARtBsAAAAADCCZgMAAACAETQbAAAAAIzwWJZlBbsIAAAAAOGHdzYAAAAAGEGzAQAAAMAImg0AAAAARtBsAAAAADCCZgMAAACAETQbAAAAAIyg2QAAAABgBM0GAAAAACNoNgAAAAAY8f8AH2qrI/Ce6CgAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Preprocess for CNN (keep as 28x28 grayscale)\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test  = x_test.astype('float32')  / 255.0"
      ],
      "metadata": {
        "id": "Hab0hnyGGvFF"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add channel dim\n",
        "x_train = np.expand_dims(x_train, -1)  # shape (N,28,28,1)\n",
        "x_test  = np.expand_dims(x_test, -1)\n",
        "\n",
        "num_classes = 10\n",
        "y_train_cat = utils.to_categorical(y_train, num_classes)\n",
        "y_test_cat  = utils.to_categorical(y_test, num_classes)"
      ],
      "metadata": {
        "id": "qGIxErv7Gyd1"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_cnn_mnist(input_shape=(28,28,1), num_classes=10):\n",
        "    model = models.Sequential(name=\"Simple_CNN_MNIST\")\n",
        "    model.add(layers.Conv2D(32, (5,5), activation='relu', padding='same', input_shape=input_shape))\n",
        "    model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(layers.Conv2D(64, (5,5), activation='relu', padding='same'))\n",
        "    model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
        "    # Fix: Change kernel size from (5,5) to (3,3)\n",
        "    model.add(layers.Conv2D(64, (3,3), activation='relu', padding='same'))\n",
        "    model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(100, activation='relu'))\n",
        "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
        "    return model\n",
        "\n",
        "model = build_cnn_mnist()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OTl1VCBG2jg",
        "outputId": "b7f1af4d-68ae-4128-8bdf-b3c49fa60d17"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Compile & Train\n",
        "batch_size = 128\n",
        "epochs = 8\n",
        "\n",
        "model.compile(optimizer=optimizers.Adam(),\n",
        "              loss=losses.CategoricalCrossentropy(),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "p7er6UfEG4NN"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# simple callbacks\n",
        "cb = [\n",
        "    callbacks.ModelCheckpoint(\"best_cnn_mnist.h5\", save_best_only=True, monitor='val_accuracy'),\n",
        "    callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1)\n",
        "]\n",
        "\n",
        "history = model.fit(x_train, y_train_cat,\n",
        "                    validation_split=0.1,\n",
        "                    epochs=epochs,\n",
        "                    batch_size=batch_size,\n",
        "                    callbacks=cb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IEpyszstHCNL",
        "outputId": "850b4f9b-a5c4-46b0-ad32-adc005e7fcee"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 323ms/step - accuracy: 0.8356 - loss: 0.5277"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 333ms/step - accuracy: 0.8358 - loss: 0.5270 - val_accuracy: 0.9777 - val_loss: 0.0816 - learning_rate: 0.0010\n",
            "Epoch 2/8\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 316ms/step - accuracy: 0.9808 - loss: 0.0630"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 329ms/step - accuracy: 0.9808 - loss: 0.0630 - val_accuracy: 0.9877 - val_loss: 0.0464 - learning_rate: 0.0010\n",
            "Epoch 3/8\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 314ms/step - accuracy: 0.9879 - loss: 0.0393"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 323ms/step - accuracy: 0.9879 - loss: 0.0393 - val_accuracy: 0.9912 - val_loss: 0.0323 - learning_rate: 0.0010\n",
            "Epoch 4/8\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 326ms/step - accuracy: 0.9908 - loss: 0.0288 - val_accuracy: 0.9893 - val_loss: 0.0369 - learning_rate: 0.0010\n",
            "Epoch 5/8\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 315ms/step - accuracy: 0.9927 - loss: 0.0218\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 324ms/step - accuracy: 0.9927 - loss: 0.0218 - val_accuracy: 0.9897 - val_loss: 0.0325 - learning_rate: 0.0010\n",
            "Epoch 6/8\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 315ms/step - accuracy: 0.9961 - loss: 0.0124"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 327ms/step - accuracy: 0.9961 - loss: 0.0124 - val_accuracy: 0.9935 - val_loss: 0.0247 - learning_rate: 5.0000e-04\n",
            "Epoch 7/8\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 325ms/step - accuracy: 0.9979 - loss: 0.0079 - val_accuracy: 0.9922 - val_loss: 0.0294 - learning_rate: 5.0000e-04\n",
            "Epoch 8/8\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 314ms/step - accuracy: 0.9984 - loss: 0.0058\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 323ms/step - accuracy: 0.9984 - loss: 0.0058 - val_accuracy: 0.9933 - val_loss: 0.0297 - learning_rate: 5.0000e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "id": "6955745f",
        "outputId": "db7b2332-06ae-4249-fa89-a09c13ef03dd"
      },
      "source": [
        "# Build the model to inspect its architecture and output shapes\n",
        "model = build_cnn_mnist()\n",
        "model.summary()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"Simple_CNN_MNIST\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Simple_CNN_MNIST\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m832\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_6 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m51,264\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_7 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │       \u001b[38;5;34m102,464\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_8 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m576\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m57,700\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,010\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">832</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">51,264</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">102,464</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">57,700</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,010</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m213,270\u001b[0m (833.09 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">213,270</span> (833.09 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m213,270\u001b[0m (833.09 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">213,270</span> (833.09 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Evaluate\n",
        "model.load_weights(\"best_cnn_mnist.h5\")\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test_cat, verbose=2)\n",
        "print(f\"Test acc: {test_acc:.4f}, loss: {test_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "589eQZcyNO8t",
        "outputId": "ff5aa0f7-fdb6-4ae2-fefe-14560e187895"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 - 8s - 26ms/step - accuracy: 0.9930 - loss: 0.0217\n",
            "Test acc: 0.9930, loss: 0.0217\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion matrix / classification report\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "y_pred = model.predict(x_test)\n",
        "y_pred_labels = np.argmax(y_pred, axis=1)\n",
        "print(classification_report(y_test, y_pred_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gEZQoxU_NV50",
        "outputId": "d202a487-7735-48cb-b3ea-047302194107"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99       980\n",
            "           1       1.00      1.00      1.00      1135\n",
            "           2       0.99      1.00      0.99      1032\n",
            "           3       0.99      0.99      0.99      1010\n",
            "           4       1.00      1.00      1.00       982\n",
            "           5       0.99      0.99      0.99       892\n",
            "           6       1.00      0.99      0.99       958\n",
            "           7       0.99      0.99      0.99      1028\n",
            "           8       0.99      0.99      0.99       974\n",
            "           9       0.99      0.99      0.99      1009\n",
            "\n",
            "    accuracy                           0.99     10000\n",
            "   macro avg       0.99      0.99      0.99     10000\n",
            "weighted avg       0.99      0.99      0.99     10000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Transfer Learning examples (adapt MNIST to 224x224x3)\n",
        "# Convert grayscale 28x28 -> 224x224x3 by resizing and repeating channel\n",
        "import tensorflow.keras.backend as K\n",
        "def mnist_to_rgb224(x):\n",
        "    # x: (N,28,28) or (N,28,28,1)\n",
        "    import cv2\n",
        "    N = x.shape[0]\n",
        "    out = np.zeros((N,224,224,3), dtype=np.float32)\n",
        "    for i in range(N):\n",
        "        img = x[i].squeeze() * 255.0\n",
        "        img_resized = cv2.resize(img, (224,224))\n",
        "        img_rgb = np.stack([img_resized, img_resized, img_resized], axis=-1)\n",
        "        out[i] = img_rgb\n",
        "    return out"
      ],
      "metadata": {
        "id": "TgIGoFF8NcP6"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We'll use a small subset for the TL demo to keep runtime low\n",
        "N_demo = 2000\n",
        "x_tl_train = mnist_to_rgb224(x_train[:N_demo])\n",
        "y_tl_train = y_train[:N_demo]\n",
        "x_tl_val   = mnist_to_rgb224(x_test[:1000])\n",
        "y_tl_val   = y_test[:1000]"
      ],
      "metadata": {
        "id": "4-2KTgAQNgJd"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# VGG16-based classifier (feature extractor)\n",
        "vgg_base = VGG16(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
        "vgg_base.trainable = False  # freeze\n",
        "\n",
        "vgg_model = models.Sequential([\n",
        "    layers.Input((224,224,3)),\n",
        "    layers.Lambda(vgg_preprocess),\n",
        "    vgg_base,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dropout(0.3),\n",
        "    layers.Dense(num_classes, activation='softmax')\n",
        "])\n",
        "vgg_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "print(\"Training VGG-based model (demo subset)...\")\n",
        "vgg_model.fit(x_tl_train, y_tl_train, validation_data=(x_tl_val, y_tl_val), epochs=5, batch_size=64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2jBjuS7Nk7N",
        "outputId": "3f3a3201-82dc-460a-8f26-9bec457c97c0"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m58889256/58889256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Training VGG-based model (demo subset)...\n",
            "Epoch 1/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1762s\u001b[0m 56s/step - accuracy: 0.2481 - loss: 3.1241 - val_accuracy: 0.7750 - val_loss: 0.7202\n",
            "Epoch 2/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1793s\u001b[0m 57s/step - accuracy: 0.7784 - loss: 0.7084 - val_accuracy: 0.8500 - val_loss: 0.4558\n",
            "Epoch 3/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1791s\u001b[0m 56s/step - accuracy: 0.8301 - loss: 0.5420 - val_accuracy: 0.8800 - val_loss: 0.3663\n",
            "Epoch 4/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1794s\u001b[0m 57s/step - accuracy: 0.8804 - loss: 0.3823 - val_accuracy: 0.9090 - val_loss: 0.2983\n",
            "Epoch 5/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1822s\u001b[0m 57s/step - accuracy: 0.9189 - loss: 0.2820 - val_accuracy: 0.9210 - val_loss: 0.2591\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x790b9932ddc0>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ResNet50-based classifier (feature extractor)\n",
        "res_base = ResNet50(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
        "res_base.trainable = False\n",
        "\n",
        "res_model = models.Sequential([\n",
        "    layers.Input((224,224,3)),\n",
        "    layers.Lambda(resnet_preprocess),\n",
        "    res_base,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dropout(0.3),\n",
        "    layers.Dense(num_classes, activation='softmax')\n",
        "])\n",
        "res_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "print(\"Training ResNet50-based model (demo subset)...\")\n",
        "res_model.fit(x_tl_train, y_tl_train, validation_data=(x_tl_val, y_tl_val), epochs=5, batch_size=64)\n",
        "\n",
        "print(\"All done.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWeJhVzTwjQs",
        "outputId": "8cb38442-43ae-40cb-d808-769d2436882a"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Training ResNet50-based model (demo subset)...\n",
            "Epoch 1/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m558s\u001b[0m 17s/step - accuracy: 0.4522 - loss: 1.7023 - val_accuracy: 0.7870 - val_loss: 0.6161\n",
            "Epoch 2/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m576s\u001b[0m 18s/step - accuracy: 0.8382 - loss: 0.5081 - val_accuracy: 0.8870 - val_loss: 0.3773\n",
            "Epoch 3/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m620s\u001b[0m 18s/step - accuracy: 0.8947 - loss: 0.3447 - val_accuracy: 0.9200 - val_loss: 0.2881\n",
            "Epoch 4/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m540s\u001b[0m 17s/step - accuracy: 0.9177 - loss: 0.2689 - val_accuracy: 0.9220 - val_loss: 0.2485\n",
            "Epoch 5/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m583s\u001b[0m 18s/step - accuracy: 0.9313 - loss: 0.2340 - val_accuracy: 0.9380 - val_loss: 0.2125\n",
            "All done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# TP CNN - PyTorch\n",
        "# =========================\n",
        "\n",
        "# 0. Imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAYIol2Y80kt",
        "outputId": "e31cb4a9-262b-40ac-a0d9-30e5d30d8f64"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Data transforms\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(), # will produce [0,1] and shape (1,28,28)\n",
        "    # Optionally normalize: transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset  = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=2)\n",
        "test_loader  = DataLoader(test_dataset, batch_size=256, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vmgkd2kg9CZa",
        "outputId": "eb5ce8c5-dc44-4f62-b75f-b6412bdae18e"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 134MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 31.0MB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 84.6MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 4.19MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self, input_shape=(1,28,28), num_classes=10):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=5, padding=2)  # padding=2 → \"same\"\n",
        "        self.pool  = nn.MaxPool2d(2,2)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5, padding=2)\n",
        "        self.conv3 = nn.Conv2d(64, 64, kernel_size=5, padding=2)\n",
        "\n",
        "        # calcul automatique de la taille du flatten\n",
        "        with torch.no_grad():\n",
        "            dummy = torch.zeros(1, *input_shape)\n",
        "            out = self._forward_conv(dummy)\n",
        "            n_features = out.view(1, -1).size(1)\n",
        "\n",
        "        self.fc4 = nn.Linear(n_features, 100)\n",
        "        self.fc5 = nn.Linear(100, num_classes)\n",
        "\n",
        "    def _forward_conv(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = self.pool(x)\n",
        "        return x\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self._forward_conv(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.fc4(x))\n",
        "        x = self.fc5(x)\n",
        "        return F.log_softmax(x, dim=1)\n"
      ],
      "metadata": {
        "id": "R8bNoGzD9IDf"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = SimpleCNN().to(device)\n",
        "print(model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CK2N90Ee9MgB",
        "outputId": "b6e35cfe-b0f9-4587-a1c0-d78b11a741fa"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SimpleCNN(\n",
            "  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "  (conv3): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "  (fc4): Linear(in_features=576, out_features=100, bias=True)\n",
            "  (fc5): Linear(in_features=100, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Training setup\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "criterion = nn.NLLLoss()"
      ],
      "metadata": {
        "id": "psfVtcse-TUT"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(model, loader, optimizer, criterion):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for data, target in loader:\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() * data.size(0)\n",
        "    return total_loss / len(loader.dataset)"
      ],
      "metadata": {
        "id": "0wBTdUeI-WxY"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, loader, criterion):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    preds = []\n",
        "    labels = []\n",
        "    with torch.no_grad():\n",
        "        for data, target in loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            total_loss += loss.item() * data.size(0)\n",
        "            preds.append(output.argmax(dim=1).cpu().numpy())\n",
        "            labels.append(target.cpu().numpy())\n",
        "    preds = np.concatenate(preds)\n",
        "    labels = np.concatenate(labels)\n",
        "    acc = (preds == labels).mean()\n",
        "    return total_loss/len(loader.dataset), acc, preds, labels"
      ],
      "metadata": {
        "id": "DBvkmmj7-ahz"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Run training\n",
        "epochs = 8\n",
        "for epoch in range(1, epochs+1):\n",
        "    train_loss = train_epoch(model, train_loader, optimizer, criterion)\n",
        "    val_loss, val_acc, _, _ = evaluate(model, test_loader, criterion)\n",
        "    print(f\"Epoch {epoch}: train_loss={train_loss:.4f} val_loss={val_loss:.4f} val_acc={val_acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EUh--uKm-eLw",
        "outputId": "a7db2486-54b4-496b-b0dd-983419b07549"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: train_loss=0.2262 val_loss=0.0491 val_acc=0.9840\n",
            "Epoch 2: train_loss=0.0520 val_loss=0.0395 val_acc=0.9878\n",
            "Epoch 3: train_loss=0.0349 val_loss=0.0263 val_acc=0.9913\n",
            "Epoch 4: train_loss=0.0261 val_loss=0.0239 val_acc=0.9913\n",
            "Epoch 5: train_loss=0.0209 val_loss=0.0325 val_acc=0.9889\n",
            "Epoch 6: train_loss=0.0169 val_loss=0.0238 val_acc=0.9922\n",
            "Epoch 7: train_loss=0.0133 val_loss=0.0253 val_acc=0.9926\n",
            "Epoch 8: train_loss=0.0123 val_loss=0.0295 val_acc=0.9907\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Final evaluation + classification report\n",
        "_, acc, preds, labels = evaluate(model, test_loader, criterion)\n",
        "print(\"Test accuracy:\", acc)\n",
        "print(classification_report(labels, preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "niQ6sAr3EaCO",
        "outputId": "aa01b3e1-24b8-42b5-cf79-29c510fea577"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.9907\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      1.00       980\n",
            "           1       1.00      0.99      0.99      1135\n",
            "           2       0.99      0.99      0.99      1032\n",
            "           3       0.97      1.00      0.98      1010\n",
            "           4       0.99      0.99      0.99       982\n",
            "           5       1.00      0.99      0.99       892\n",
            "           6       1.00      0.98      0.99       958\n",
            "           7       0.99      0.99      0.99      1028\n",
            "           8       0.99      0.99      0.99       974\n",
            "           9       0.99      0.99      0.99      1009\n",
            "\n",
            "    accuracy                           0.99     10000\n",
            "   macro avg       0.99      0.99      0.99     10000\n",
            "weighted avg       0.99      0.99      0.99     10000\n",
            "\n"
          ]
        }
      ]
    }
  ]
}